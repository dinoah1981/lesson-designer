---
phase: 03-single-persona-feedback
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - .claude/skills/lesson-designer/scripts/generate_revision_plan.py
  - .claude/skills/lesson-designer/SKILL.md
autonomous: true

must_haves:
  truths:
    - "Tool generates teacher-readable revision plan from persona feedback"
    - "Revision plan presents critical changes with approve/reject options"
    - "SKILL.md documents Stage 3.5 persona feedback workflow"
  artifacts:
    - path: ".claude/skills/lesson-designer/scripts/generate_revision_plan.py"
      provides: "Revision plan generator from persona feedback"
      exports: ["generate_revision_plan", "render_revision_markdown"]
    - path: ".claude/skills/lesson-designer/SKILL.md"
      provides: "Stage 3.5 workflow documentation"
      contains: "Stage 3.5"
  key_links:
    - from: "generate_revision_plan.py"
      to: "persona_evaluator.py"
      via: "reads feedback JSON output"
      pattern: "feedback.*json"
    - from: "SKILL.md"
      to: "Stage 3.5"
      via: "workflow stage documentation"
      pattern: "persona.*feedback"
---

<objective>
Create the revision plan generator and integrate persona feedback into the SKILL.md workflow as Stage 3.5.

Purpose: Transform structured persona feedback into a teacher-readable revision plan with clear approve/reject options. Document the complete feedback loop workflow so Claude can execute Stage 3.5 between lesson design validation (Stage 3b) and file generation (Stage 5).

Output:
- scripts/generate_revision_plan.py - Aggregates feedback, prioritizes changes, renders Markdown
- SKILL.md updated with Stage 3.5 documentation
</objective>

<execution_context>
@C:\Users\david\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\david\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-single-persona-feedback/03-RESEARCH.md

# From Plan 01
@.claude/skills/lesson-designer/personas/struggling_learner.json
@.claude/skills/lesson-designer/scripts/persona_evaluator.py

# Current workflow
@.claude/skills/lesson-designer/SKILL.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create revision plan generator script</name>
  <files>
    .claude/skills/lesson-designer/scripts/generate_revision_plan.py
  </files>
  <action>
Create generate_revision_plan.py that transforms persona feedback into a teacher-readable revision plan.

Script structure:
```python
#!/usr/bin/env python3
"""
Generate revision plan from persona feedback.

Usage:
    python generate_revision_plan.py <feedback_json> <output_json> [--markdown <output_md>]

Example:
    python generate_revision_plan.py \
        .lesson-designer/sessions/{session_id}/03_feedback_struggling_learner.json \
        .lesson-designer/sessions/{session_id}/03_revision_plan.json \
        --markdown .lesson-designer/sessions/{session_id}/03_revision_plan.md
"""

import json
import argparse
from datetime import datetime
from pathlib import Path

def aggregate_feedback(feedback_files):
    """Combine feedback from all personas (Phase 3: just 1)."""
    # Load feedback files
    # Extract all concerns
    # Return aggregated structure

def prioritize_revisions(concerns):
    """Organize by severity, group by element."""
    # Sort by severity (high > medium > low)
    # Group by element for coherent presentation
    # Return prioritized list

def generate_revision_plan(lesson_path, feedback_paths, output_path):
    """Create structured revision plan with specific changes."""
    # Load lesson and feedback
    # Aggregate concerns
    # Prioritize by severity
    # Structure into:
    #   - critical_changes (high severity)
    #   - optional_improvements (medium severity)
    #   - requires_teacher_decision (low severity or deferred items)
    # Include current_state, proposed_change, rationale, implementation_notes
    # Save revision plan JSON

def render_revision_markdown(revision_plan, lesson, output_md_path):
    """Generate teacher-readable Markdown from revision plan."""
    # Template structure:
    # # Revision Plan: {lesson_title}
    # **Lesson:** {title}
    # **Generated:** {date}
    # **Personas consulted:** {persona_names}
    #
    # ## Summary
    # {concern_count} concerns identified, {critical_count} critical
    #
    # ## Critical Changes (RECOMMENDED)
    # ### Change 1: {title}
    # **Element:** {element}
    # **Severity:** HIGH
    # **Persona:** {persona_name}
    # **Current State:** {description}
    # **Proposed Change:** {change}
    # **Rationale:** {rationale}
    # **Impact if not addressed:** {impact}
    # **Teacher decision:**
    # - [ ] Approve as written
    # - [ ] Approve with modifications: ___
    # - [ ] Reject (reason: ___)
    #
    # ## Optional Improvements (CONSIDER)
    # ### Change N: {title}
    # ...
    #
    # ## Requires Teacher Context (LOW PRIORITY)
    # ...
    #
    # ## Approval Summary
    # **Critical changes requiring approval:** {count}
    # **Estimated time impact:** +{minutes} minutes
```

Key functions:
- aggregate_feedback(): handles 1 persona now, N personas in Phase 4
- prioritize_revisions(): severity-based sorting
- generate_revision_plan(): creates JSON structure
- render_revision_markdown(): creates teacher-readable output
- apply_revisions(): applies approved changes to lesson JSON (for Phase 3 completion)

The revision plan JSON should include status fields for tracking teacher decisions:
- status: "pending" | "approved" | "approved_with_modifications" | "rejected"
- teacher_notes: str (optional modifications or rejection reason)

**CRITICAL: apply_revisions() Implementation Specification**

The apply_revisions() function must read approved revisions and modify the lesson JSON. Here is the implementation specification:

```python
def apply_revisions(lesson_path, revision_plan_path, output_path):
    """
    Apply teacher-approved revisions to lesson JSON.

    Args:
        lesson_path: Path to 04_lesson_final.json
        revision_plan_path: Path to 03_revision_plan.json with teacher decisions
        output_path: Path to write revised lesson (can be same as lesson_path)
    """
    # Load files
    lesson = json.load(open(lesson_path))
    revision_plan = json.load(open(revision_plan_path))

    # Track what was applied
    applied = []
    skipped = []

    # Process each change category
    for change in revision_plan.get('critical_changes', []) + revision_plan.get('optional_improvements', []):
        # Skip non-approved changes
        if change.get('status') not in ['approved', 'approved_with_modifications']:
            skipped.append(change['id'])
            continue

        # Route to appropriate handler based on element type
        element = change['element']

        if element == 'vocabulary':
            _apply_vocabulary_change(lesson, change)
        elif element == 'scaffolding':
            _apply_scaffolding_change(lesson, change)
        elif element == 'pacing':
            _apply_pacing_change(lesson, change)
        elif element == 'instructions':
            _apply_instructions_change(lesson, change)
        else:
            # Generic change - store in lesson metadata for manual handling
            _apply_generic_change(lesson, change)

        applied.append(change['id'])

    # Add revision metadata
    lesson['_revision_applied'] = {
        'date': datetime.now().isoformat(),
        'revision_plan': str(revision_plan_path),
        'changes_applied': applied,
        'changes_skipped': skipped
    }

    # Write output
    json.dump(lesson, open(output_path, 'w'), indent=2)
    return {'applied': applied, 'skipped': skipped}


def _apply_vocabulary_change(lesson, change):
    """
    Add vocabulary definitions to lesson.

    Change structure expected:
    {
        "element": "vocabulary",
        "terms_to_define": ["bias", "reliability", "perspective"],
        "implementation": {
            "add_definitions": true,
            "definitions": {
                "bias": {"definition": "...", "example": "...", "visual": "..."},
                ...
            }
        }
    }

    Modifies lesson:
    - lesson['vocabulary'] list: adds 'definition', 'example', 'visual' fields to each term
    - lesson['activities']: adds pre-teaching activity if not present
    """
    impl = change.get('implementation', {})

    # Ensure vocabulary section exists
    if 'vocabulary' not in lesson:
        lesson['vocabulary'] = []

    # Add definitions to existing vocabulary items
    if impl.get('add_definitions'):
        definitions = impl.get('definitions', {})
        for vocab_item in lesson['vocabulary']:
            term = vocab_item.get('term', '')
            if term in definitions:
                vocab_item['definition'] = definitions[term].get('definition', '')
                vocab_item['example'] = definitions[term].get('example', '')
                vocab_item['visual'] = definitions[term].get('visual', '')

    # Add pre-teaching activity if specified
    if impl.get('add_pre_teaching_activity'):
        pre_teach = {
            'name': 'Vocabulary Pre-Teaching',
            'duration': impl.get('pre_teaching_duration', 5),
            'description': 'Review key vocabulary before main lesson',
            'type': 'vocabulary_introduction',
            'terms': impl.get('terms_to_define', [])
        }
        # Insert at beginning of activities
        if 'activities' in lesson:
            lesson['activities'].insert(0, pre_teach)


def _apply_scaffolding_change(lesson, change):
    """
    Add scaffolding elements (sentence frames, worked examples, graphic organizers).

    Change structure expected:
    {
        "element": "scaffolding",
        "target_activity": "SOAP Analysis",  # Activity name to modify
        "implementation": {
            "add_sentence_frames": true,
            "sentence_frames": [
                "The speaker is ___ because ___.",
                "This source was created to ___."
            ],
            "add_worked_example": true,
            "worked_example": {
                "description": "Model SOAP analysis of Declaration of Independence",
                "content": "..."
            },
            "add_graphic_organizer": true,
            "graphic_organizer": {
                "type": "SOAP_chart",
                "template": "..."
            }
        }
    }

    Modifies lesson:
    - lesson['activities'][target]: adds 'sentence_frames', 'worked_example', 'graphic_organizer' fields
    - lesson['materials']: adds new handout if graphic organizer specified
    """
    impl = change.get('implementation', {})
    target_name = change.get('target_activity', '')

    # Find target activity
    for activity in lesson.get('activities', []):
        if activity.get('name') == target_name or target_name in activity.get('name', ''):
            # Add sentence frames
            if impl.get('add_sentence_frames'):
                activity['sentence_frames'] = impl.get('sentence_frames', [])
                activity['include_sentence_frames'] = True

            # Add worked example
            if impl.get('add_worked_example'):
                activity['worked_example'] = impl.get('worked_example', {})
                activity['include_worked_example'] = True

            # Add graphic organizer
            if impl.get('add_graphic_organizer'):
                activity['graphic_organizer'] = impl.get('graphic_organizer', {})

            break

    # Add to materials list if graphic organizer added
    if impl.get('add_graphic_organizer'):
        if 'materials' not in lesson:
            lesson['materials'] = []
        lesson['materials'].append({
            'name': f"{impl['graphic_organizer'].get('type', 'Graphic Organizer')} Handout",
            'type': 'handout',
            'for_activity': target_name
        })


def _apply_pacing_change(lesson, change):
    """
    Add break points or split activities for better pacing.

    Change structure expected:
    {
        "element": "pacing",
        "target_activity": "Document Analysis",
        "implementation": {
            "add_break_point": true,
            "break_point": {
                "at_minute": 12,
                "type": "turn_and_talk",
                "prompt": "Share one thing you noticed with your partner"
            },
            "split_activity": false  # Alternative: split into two activities
        }
    }

    Modifies lesson:
    - lesson['activities'][target]: adds 'break_points' array
    - OR splits activity into two separate activities
    """
    impl = change.get('implementation', {})
    target_name = change.get('target_activity', '')

    for i, activity in enumerate(lesson.get('activities', [])):
        if activity.get('name') == target_name or target_name in activity.get('name', ''):
            if impl.get('add_break_point'):
                # Add break point within activity
                if 'break_points' not in activity:
                    activity['break_points'] = []
                activity['break_points'].append(impl.get('break_point', {}))

            elif impl.get('split_activity'):
                # Split into two activities
                split_config = impl.get('split_config', {})
                original_duration = activity.get('duration', 20)

                # First half
                activity['duration'] = split_config.get('first_duration', original_duration // 2)
                activity['name'] = f"{activity['name']} - Part 1"

                # Second half (insert after)
                second_half = {
                    'name': f"{target_name} - Part 2",
                    'duration': split_config.get('second_duration', original_duration // 2),
                    'description': split_config.get('second_description', 'Continue activity'),
                    'type': activity.get('type', 'activity')
                }
                lesson['activities'].insert(i + 1, second_half)

            break


def _apply_instructions_change(lesson, change):
    """
    Modify instruction clarity (numbered steps, simplify language).

    Change structure expected:
    {
        "element": "instructions",
        "target_activity": "Activity Name",
        "implementation": {
            "add_numbered_steps": true,
            "numbered_steps": ["Step 1: ...", "Step 2: ...", "Step 3: ..."],
            "add_checklist": true,
            "checklist": ["Did you...?", "Did you...?"]
        }
    }
    """
    impl = change.get('implementation', {})
    target_name = change.get('target_activity', '')

    for activity in lesson.get('activities', []):
        if activity.get('name') == target_name or target_name in activity.get('name', ''):
            if impl.get('add_numbered_steps'):
                activity['instructions'] = impl.get('numbered_steps', [])
                activity['instruction_format'] = 'numbered'

            if impl.get('add_checklist'):
                activity['completion_checklist'] = impl.get('checklist', [])

            break


def _apply_generic_change(lesson, change):
    """
    Store unhandled change types in lesson metadata for manual review.
    """
    if '_pending_manual_changes' not in lesson:
        lesson['_pending_manual_changes'] = []

    lesson['_pending_manual_changes'].append({
        'id': change.get('id'),
        'element': change.get('element'),
        'description': change.get('proposed_change'),
        'rationale': change.get('rationale')
    })
```

**Revision Plan JSON Structure for apply_revisions():**

The revision plan JSON produced by generate_revision_plan() must include:

```json
{
    "lesson_title": "Analyzing Historical Sources",
    "generated_date": "2026-01-26",
    "personas_consulted": ["struggling_learner_ell"],
    "critical_changes": [
        {
            "id": "change_001",
            "element": "vocabulary",
            "severity": "high",
            "status": "pending",
            "current_state": "3 terms lack definitions (bias, reliability, perspective)",
            "proposed_change": "Add vocabulary pre-teaching section",
            "rationale": "96% of struggling readers have vocabulary gaps",
            "implementation": {
                "add_definitions": true,
                "definitions": {
                    "bias": {"definition": "...", "example": "...", "visual": "..."}
                },
                "add_pre_teaching_activity": true,
                "pre_teaching_duration": 5,
                "terms_to_define": ["bias", "reliability", "perspective"]
            },
            "teacher_notes": ""
        }
    ],
    "optional_improvements": [...],
    "requires_teacher_decision": [...]
}
```

Each change MUST have an `implementation` object that apply_revisions() can parse and execute. The implementation structure varies by element type as shown above.
  </action>
  <verify>
python -c "
import sys
sys.path.insert(0, '.claude/skills/lesson-designer/scripts')
from generate_revision_plan import aggregate_feedback, prioritize_revisions, generate_revision_plan, render_revision_markdown, apply_revisions

# Create test feedback
feedback = {
    'persona': 'struggling_learner_ell',
    'persona_name': 'Alex',
    'concerns': [
        {'element': 'vocabulary', 'issue': 'Terms lack definitions', 'severity': 'high', 'recommendation': {'change': 'Add definitions', 'rationale': 'Vocab gaps'}},
        {'element': 'pacing', 'issue': 'Activity too long', 'severity': 'medium', 'recommendation': {'change': 'Add break', 'rationale': 'Attention span'}}
    ]
}
import json
import tempfile
with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
    json.dump(feedback, f)
    fb_path = f.name

agg = aggregate_feedback([fb_path])
prioritized = prioritize_revisions(agg['all_concerns'])
assert len(prioritized) == 2
assert prioritized[0]['severity'] == 'high'  # High severity first

# Test apply_revisions exists and is callable
import inspect
sig = inspect.signature(apply_revisions)
params = list(sig.parameters.keys())
assert 'lesson_path' in params
assert 'revision_plan_path' in params
assert 'output_path' in params
print('Revision plan generator works including apply_revisions()')
"
  </verify>
  <done>
- generate_revision_plan.py exists with all key functions
- aggregate_feedback() combines feedback from persona(s)
- prioritize_revisions() sorts by severity
- generate_revision_plan() creates structured JSON with implementation objects
- render_revision_markdown() creates teacher-readable output
- apply_revisions() applies approved changes with element-specific handlers:
  - _apply_vocabulary_change(): adds definitions, pre-teaching activities
  - _apply_scaffolding_change(): adds sentence_frames, worked_example, graphic_organizer
  - _apply_pacing_change(): adds break_points or splits activities
  - _apply_instructions_change(): adds numbered_steps, checklists
  - _apply_generic_change(): stores unhandled types for manual review
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Stage 3.5 to SKILL.md workflow</name>
  <files>
    .claude/skills/lesson-designer/SKILL.md
  </files>
  <action>
Update SKILL.md to document Stage 3.5: Persona Feedback & Revision.

Insert Stage 3.5 after Stage 3b (Validate Cognitive Rigor) and before Stage 5 (Generate Materials).

Add this section to SKILL.md:

```markdown
### Stage 3.5: Persona Feedback & Revision

**Purpose:** Evaluate lesson design through struggling learner persona and apply teacher-approved revisions before generating materials.

**Inputs:**
- Validated lesson design from Stage 3b (`04_lesson_final.json`)
- Persona definition (`.claude/skills/lesson-designer/personas/struggling_learner.json`)

**Process:**

#### Step 1: Run Persona Evaluation

```bash
python .claude/skills/lesson-designer/scripts/persona_evaluator.py \
    .lesson-designer/sessions/{session_id}/04_lesson_final.json \
    .claude/skills/lesson-designer/personas/struggling_learner.json \
    .lesson-designer/sessions/{session_id}/03_feedback_struggling_learner.json
```

This produces structured feedback JSON with:
- Accessibility rating (1-5 scale)
- Strengths (what works well for struggling learners)
- Concerns (issues with severity ratings)
- Recommendations (specific changes with rationale)

#### Step 2: Generate Revision Plan

```bash
python .claude/skills/lesson-designer/scripts/generate_revision_plan.py \
    .lesson-designer/sessions/{session_id}/03_feedback_struggling_learner.json \
    .lesson-designer/sessions/{session_id}/03_revision_plan.json \
    --markdown .lesson-designer/sessions/{session_id}/03_revision_plan.md
```

This produces:
- `03_revision_plan.json` - Structured revision plan
- `03_revision_plan.md` - Teacher-readable revision plan

#### Step 3: Present Revision Plan to Teacher

Present the Markdown revision plan to the teacher with this format:

```
Based on struggling learner feedback, I've identified {N} recommended changes to improve accessibility.

[Show 03_revision_plan.md content]

Do you approve the critical changes?
1. {Change 1 summary}
2. {Change 2 summary}

Reply "approve all" or specify which changes to approve/reject.
```

Wait for teacher response before proceeding.

#### Step 4: Apply Approved Revisions

If teacher approves changes:

```python
from generate_revision_plan import apply_revisions

apply_revisions(
    lesson_path='.lesson-designer/sessions/{session_id}/04_lesson_final.json',
    revision_plan_path='.lesson-designer/sessions/{session_id}/03_revision_plan.json',
    output_path='.lesson-designer/sessions/{session_id}/04_lesson_final.json'  # Overwrites with revised version
)
```

If teacher rejects all changes, proceed with original lesson design.

#### Step 5: Log Revision Decision

Update `03_revision_plan.json` with teacher decisions:
- status: "approved" | "approved_with_modifications" | "rejected"
- teacher_notes: Any modifications or rejection reasons

**Outputs:**
- `03_feedback_struggling_learner.json` - Persona feedback
- `03_revision_plan.json` - Revision plan with teacher decisions
- `03_revision_plan.md` - Teacher-readable plan
- `04_lesson_final.json` - Updated with approved revisions

**Evaluation Criteria:**

The struggling learner persona ("Alex") evaluates:
1. **Vocabulary Accessibility** - Tier 2/3 terms defined? Reading level appropriate?
2. **Instruction Clarity** - Steps numbered? <3 steps or checklist provided?
3. **Scaffolding Adequacy** - Models for writing tasks? Sentence frames? Graphic organizers?
4. **Pacing Appropriateness** - Activities <20 min? Break points for longer activities?
5. **Engagement Accessibility** - Multiple entry points? Choice opportunities?

**When to Skip Stage 3.5:**

Stage 3.5 can be skipped if:
- Teacher explicitly opts out (`"skip_persona_feedback": true` in 01_input.json)
- Lesson is specifically designed for advanced learners only

Default: Always run Stage 3.5 for inclusive lesson design.

**Requirements Covered:**
- PERS-01 (partial): Tool runs lesson through struggling learner persona
- PERS-02: Persona provides reaction describing likely response
- PERS-03: Persona provides specific pedagogical recommendations
- PERS-04: Tool proposes revisions; teacher confirms before finalizing

**Next:** Stage 5 (Generate Materials)
```

Also update:
1. Workflow Overview checklist - add Stage 3.5
2. Complete Workflow Checklist - add Stage 3.5 section
3. State Directory Structure - add new files (03_feedback_*, 03_revision_plan.*)
4. Quick Reference - add persona_evaluator.py and generate_revision_plan.py commands
  </action>
  <verify>
grep -q "Stage 3.5" .claude/skills/lesson-designer/SKILL.md && \
grep -q "persona_evaluator.py" .claude/skills/lesson-designer/SKILL.md && \
grep -q "generate_revision_plan.py" .claude/skills/lesson-designer/SKILL.md && \
echo "SKILL.md updated with Stage 3.5"
  </verify>
  <done>
- SKILL.md contains Stage 3.5: Persona Feedback & Revision section
- Workflow Overview checklist includes Stage 3.5
- Complete Workflow Checklist includes Stage 3.5 steps
- State Directory Structure shows new files (03_feedback_*, 03_revision_plan.*)
- Quick Reference includes new script commands
  </done>
</task>

</tasks>

<verification>
End-to-end test of revision plan generation:

```bash
# Create test feedback file
python -c "
import json
feedback = {
    'persona': 'struggling_learner_ell',
    'persona_name': 'Alex',
    'evaluation_date': '2026-01-26',
    'overall_assessment': {
        'accessibility_rating': '2/5',
        'summary': 'Lesson has barriers for struggling learners',
        'primary_concern': 'Vocabulary lacks definitions'
    },
    'strengths': [
        {'element': 'activity_variety', 'observation': 'Mix of activities', 'why_helpful': 'Multiple entry points'}
    ],
    'concerns': [
        {
            'element': 'vocabulary',
            'issue': '3 terms lack definitions (bias, reliability, perspective)',
            'severity': 'high',
            'impact': 'Students cannot understand core concepts',
            'evidence': 'Vocabulary list missing definitions',
            'recommendation': {
                'change': 'Add vocabulary pre-teaching section',
                'rationale': '96% of struggling readers have vocabulary gaps',
                'implementation': 'Create handout with term, definition, example, visual'
            }
        },
        {
            'element': 'scaffolding',
            'issue': 'Writing task without sentence frames',
            'severity': 'high',
            'impact': 'Students struggle with academic writing',
            'evidence': 'SOAP analysis requires writing without model',
            'recommendation': {
                'change': 'Add sentence frames',
                'rationale': 'Explicit models reduce cognitive load',
                'implementation': 'Provide frames like \"The speaker is ___ because ___\"'
            }
        },
        {
            'element': 'pacing',
            'issue': 'Activity runs 25 min without break',
            'severity': 'medium',
            'impact': 'Cognitive overload possible',
            'evidence': 'Document Analysis is 25 min continuous',
            'recommendation': {
                'change': 'Add 2-min turn-and-talk midpoint',
                'rationale': 'Struggling readers need breaks every 10-15 min',
                'implementation': 'Insert \"Share one thing you noticed\" at minute 12'
            }
        }
    ],
    'pedagogical_notes': {
        'priority_revisions': ['Add vocabulary pre-teaching', 'Add sentence frames'],
        'deferred_to_teacher': ['Primary source reading level - teacher has context']
    }
}
json.dump(feedback, open('test_feedback.json', 'w'), indent=2)
"

# Generate revision plan
python .claude/skills/lesson-designer/scripts/generate_revision_plan.py \
    test_feedback.json \
    test_revision_plan.json \
    --markdown test_revision_plan.md

# Verify outputs
python -c "
import json
plan = json.load(open('test_revision_plan.json'))
print('Critical changes:', len(plan['critical_changes']))
print('Optional improvements:', len(plan['optional_improvements']))
assert len(plan['critical_changes']) == 2  # vocabulary and scaffolding
assert len(plan['optional_improvements']) == 1  # pacing

# Verify implementation objects exist
for change in plan['critical_changes']:
    assert 'implementation' in change, f'Missing implementation in {change[\"id\"]}'
print('All changes have implementation objects')
"

# Test apply_revisions with mock data
python -c "
import json
from pathlib import Path
import sys
sys.path.insert(0, '.claude/skills/lesson-designer/scripts')
from generate_revision_plan import apply_revisions

# Create test lesson
lesson = {
    'title': 'Test Lesson',
    'vocabulary': [
        {'term': 'bias'},
        {'term': 'reliability'}
    ],
    'activities': [
        {'name': 'Document Analysis', 'duration': 25}
    ]
}
json.dump(lesson, open('test_lesson.json', 'w'), indent=2)

# Create revision plan with approved changes
plan = {
    'critical_changes': [
        {
            'id': 'change_001',
            'element': 'vocabulary',
            'status': 'approved',
            'implementation': {
                'add_definitions': True,
                'definitions': {
                    'bias': {'definition': 'A preference that prevents objectivity', 'example': 'News source favoring one party'}
                }
            }
        }
    ],
    'optional_improvements': [
        {
            'id': 'change_002',
            'element': 'pacing',
            'status': 'approved',
            'target_activity': 'Document Analysis',
            'implementation': {
                'add_break_point': True,
                'break_point': {
                    'at_minute': 12,
                    'type': 'turn_and_talk',
                    'prompt': 'Share one observation'
                }
            }
        }
    ]
}
json.dump(plan, open('test_revision_plan_approved.json', 'w'), indent=2)

# Apply revisions
result = apply_revisions('test_lesson.json', 'test_revision_plan_approved.json', 'test_lesson_revised.json')

# Verify changes applied
revised = json.load(open('test_lesson_revised.json'))
assert revised['vocabulary'][0].get('definition') == 'A preference that prevents objectivity', 'Vocabulary definition not added'
assert 'break_points' in revised['activities'][0], 'Break point not added'
print('apply_revisions() correctly modifies lesson JSON')

# Cleanup
Path('test_lesson.json').unlink()
Path('test_revision_plan_approved.json').unlink()
Path('test_lesson_revised.json').unlink()
"

cat test_revision_plan.md | head -50

# Cleanup
rm test_feedback.json test_revision_plan.json test_revision_plan.md
```

Expected: Revision plan JSON with 2 critical changes (vocabulary, scaffolding) and 1 optional improvement (pacing). Each change has an implementation object. Markdown shows teacher-readable format with approve/reject checkboxes. apply_revisions() correctly modifies lesson JSON structure.
</verification>

<success_criteria>
- generate_revision_plan.py produces structured revision plan JSON
- Each change includes implementation object parseable by apply_revisions()
- Markdown output is teacher-readable with approve/reject options
- SKILL.md documents complete Stage 3.5 workflow
- Architecture supports Phase 4 scaling (aggregates N persona feedbacks)
- apply_revisions() function correctly modifies lesson JSON:
  - Vocabulary changes add definitions to vocabulary items
  - Scaffolding changes add sentence_frames, worked_example to activities
  - Pacing changes add break_points or split activities
  - Instructions changes add numbered_steps, checklists
  - Generic changes stored in _pending_manual_changes
</success_criteria>

<output>
After completion, create `.planning/phases/03-single-persona-feedback/03-02-SUMMARY.md`
</output>
